{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: DDQN + n-step + curriculum learning\n",
    "\n",
    "This setup extends a regular DQN by adding Double DQN (two networks: one for selecting and one for evaluating actions) to avoid Q-value overestimation, and n-step returns to let rewards propagate faster through time.\n",
    "\n",
    "I also use a simple curriculum, as I am training first on shorter poles (easy) and then gradually increasing the difficulty.\n",
    "\n",
    "Everything runs step-based, so epsilon decay and updates happen smoothly over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our basic setup cell: we import everything we need (PyTorch, NumPy, Gym, etc.) and make sure there’s a weights/ folder to store our trained models.\n",
    "\n",
    "We also fix random seeds for Python, NumPy, and PyTorch so that results are reproducible when rerunning the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x146e00370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "# checkpoints\n",
    "CHECKPOINT_DIR = \"weights\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# seeds\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our main hyperparameters are stored in a single Flags dataclass to keep the setup organized and easy to tweak.\n",
    "\n",
    "For this strategy, the most important parts are the n-step returns and the curriculum settings, since they shape how the agent learns over time.\n",
    "The n-step return (set to 5) lets the agent look multiple steps ahead instead of learning only from immediate rewards, making training smoother and more stable.\n",
    "\n",
    "The curriculum parameters control the pole length progression, the agent starts with shorter, easier poles and gradually faces longer ones.\n",
    "This helps it adapt to different dynamics and generalize better across all pole lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flags(lr=0.0005, gamma=0.99, epsilon_start=1.0, epsilon_end=0.05, epsilon_decay=300000, buffer_size=200000, batch_size=64, warmup_steps=20000, max_steps=800000, target_update_every=1000, grad_clip=8.0, n_step=5, curri_bounds=(50000, 120000), curri_ranges=((0.8, 1.2), (0.6, 1.4), (0.4, 1.8)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all main settings in one place, stored inside a Flags dataclass.\n",
    "\n",
    "@dataclass\n",
    "class Flags:\n",
    "    # learning\n",
    "    lr: float = 5e-4\n",
    "    gamma: float = 0.99\n",
    "    \n",
    "    # exploration\n",
    "    epsilon_start: float = 1.0\n",
    "    epsilon_end: float = 0.05\n",
    "    epsilon_decay: int = 300_000\n",
    "    \n",
    "    # memory\n",
    "    buffer_size: int = 200_000\n",
    "    batch_size: int = 64\n",
    "    warmup_steps: int = 20_000\n",
    "    \n",
    "    # training\n",
    "    max_steps: int = 800_000\n",
    "    target_update_every: int = 1_000\n",
    "    grad_clip: float = 8.0\n",
    "    \n",
    "    # n-step\n",
    "    n_step: int = 5\n",
    "    \n",
    "    # Curriculum learning parameters\n",
    "    curri_bounds: Tuple[int, int] = (50_000, 120_000)\n",
    "    curri_ranges: Tuple[Tuple[float, float], ...] = (\n",
    "        (0.8, 1.2), (0.6, 1.4), (0.4, 1.8)\n",
    "    )\n",
    "\n",
    "FLAGS = Flags()\n",
    "FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our Q-network, which takes in the current state (cart position, velocity, pole angle, etc.) and outputs Q-values for both possible actions: left or right.\n",
    "\n",
    "It uses two hidden layers of 128 neurons each with ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard Q-network\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Replay Buffer stores the agent’s experiences as tuples of (state, action, n-step return, next_state, done).\n",
    "Instead of learning only from the most recent transitions, the agent randomly samples batches from this memory.\n",
    "\n",
    "This helps break the correlation between consecutive steps and makes learning much more stable.\n",
    "It also allows experience reuse, as the agent can learn multiple times from valuable past situations.\n",
    "As the buffer fills up, older experiences are gradually replaced, keeping the training data fresh and relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay buffer\n",
    "# stores agent's past experiences: (state, action, n-step return, next_state, done)\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, n_step_return, next_state, done):\n",
    "        self.buffer.append((state, action, n_step_return, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size: int):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, n_step_return, next_state, done = zip(*batch)\n",
    "        return (\n",
    "            torch.tensor(np.array(state), dtype=torch.float32),\n",
    "            torch.tensor(np.array(action), dtype=torch.int64),\n",
    "            torch.tensor(np.array(n_step_return), dtype=torch.float32),\n",
    "            torch.tensor(np.array(next_state), dtype=torch.float32),\n",
    "            torch.tensor(np.array(done), dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n-step queue stores the last few transitions and calculates multi-step discounted rewards.\n",
    "Instead of updating after every single reward, the agent looks n steps ahead, helping it learn long-term effects faster and stabilize training.\n",
    "\n",
    "When an episode ends, the flush_to_buffer function ensures that any leftover steps still get added to the replay buffer with proper discounted returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-step helper\n",
    "# allows the agent to look a few steps ahead\n",
    "\n",
    "class NStepQueue:\n",
    "    def __init__(self, n: int, gamma: float):\n",
    "        self.n = n\n",
    "        self.gamma = gamma\n",
    "        self.queue = deque()  # stores tuples (state, action, reward)\n",
    "\n",
    "    def push(self, state, action, reward):\n",
    "        self.queue.append((state, action, reward))\n",
    "\n",
    "    def ready(self):\n",
    "        return len(self.queue) >= self.n\n",
    "\n",
    "    def pop_transition(self, next_state, done):\n",
    "        # compute n-step return starting from the oldest transition\n",
    "        n_step_return, discount = 0.0, 1.0\n",
    "        for i in range(min(self.n, len(self.queue))):\n",
    "            n_step_return += discount * self.queue[i][2]  # discounted reward\n",
    "            discount *= self.gamma\n",
    "        first_state, first_action, _ = self.queue[0]\n",
    "        return (first_state, first_action, n_step_return, next_state, float(done))\n",
    "\n",
    "    def pop_left(self):\n",
    "        self.queue.popleft()\n",
    "\n",
    "    def flush_to_buffer(self, last_next_state, replay: ReplayBuffer, gamma: float):\n",
    "        # when an episode ends, push all remaining transitions as terminal\n",
    "        while len(self.queue) > 0:\n",
    "            n_step_return, discount = 0.0, 1.0\n",
    "            for (_, _, reward) in self.queue:\n",
    "                n_step_return += discount * reward\n",
    "                discount *= gamma\n",
    "            first_state, first_action, _ = self.queue[0]\n",
    "            replay.push(first_state, first_action, n_step_return, last_next_state, 1.0)\n",
    "            self.pop_left()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is the heart of this strategy, which combines everything the agent needs to learn: two neural networks (online and target), the replay buffer, the optimizer, and the full training process.\n",
    "\n",
    "The main idea behind Double DQN (DDQN) is using two networks instead of one. The online network is the one that learns, it interacts with the environment, predicts Q-values, and picks the best action. The target network is a slower copy that only evaluates those actions. This separation fixes a common issue in standard DQN, where using the same network for both selection and evaluation leads to overestimated Q-values and unstable learning. In short, the online network decides, and the target network verifies.\n",
    "\n",
    "All experiences (state, action, reward, next state, done) are stored in the replay buffer, which the agent samples from randomly. This breaks correlations between consecutive steps and helps generalization.\n",
    "\n",
    "We also use n-step returns, meaning the agent looks a few steps into the future instead of only one. This makes it learn faster from delayed rewards.\n",
    "\n",
    "To make training smoother, we use curriculum learning, starting with shorter poles (easier) and gradually increasing their length. The agent first masters the easy version of the task before tackling harder ones.\n",
    "\n",
    "Finally, epsilon (ε) controls how often the agent explores randomly versus acts greedily. As training progresses, ε decays linearly, so the agent explores less and relies more on what it has learned. Periodically, the online network’s weights are copied to the target network to keep learning stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQN:\n",
    "    def __init__(self, env, flags: Flags):\n",
    "        self.env = env\n",
    "        self.FLAGS = flags\n",
    "\n",
    "        # environment dimensions\n",
    "        self.state_size = env.observation_space.shape[0]\n",
    "        self.action_size = env.action_space.n\n",
    "\n",
    "        # online + target networks (start identical)\n",
    "        self.q_network = QNetwork(self.state_size, self.action_size)\n",
    "        self.target_network = QNetwork(self.state_size, self.action_size)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "        # optimizer + loss\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=flags.lr)\n",
    "        self.criterion = nn.SmoothL1Loss()\n",
    "\n",
    "        # replay buffer and counters\n",
    "        self.replay_buffer = ReplayBuffer(flags.buffer_size)\n",
    "        self.step = 0\n",
    "        self.epsilon = flags.epsilon_start\n",
    "\n",
    "    # ε-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.as_tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "            return int(self.q_network(state_tensor).argmax(1).item())\n",
    "\n",
    "    # copy online → target\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    # one optimization step\n",
    "    def train_step(self):\n",
    "        if len(self.replay_buffer) < max(self.FLAGS.warmup_steps, self.FLAGS.batch_size):\n",
    "            return None\n",
    "\n",
    "        # sample minibatch\n",
    "        state, action, n_step_return, next_state, done = self.replay_buffer.sample(self.FLAGS.batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN: select action with online, evaluate with target\n",
    "            best_action = self.q_network(next_state).argmax(1)\n",
    "            q_next = self.target_network(next_state).gather(1, best_action.unsqueeze(1)).squeeze(1)\n",
    "            target = n_step_return + (self.FLAGS.gamma ** self.FLAGS.n_step) * (1.0 - done) * q_next\n",
    "\n",
    "        q_values = self.q_network(state).gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "        loss = self.criterion(q_values, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.q_network.parameters(), self.FLAGS.grad_clip)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return float(loss.item())\n",
    "\n",
    "    # full training loop\n",
    "    def train(self, save_path=\"weights/ddqn_model.pth\"):\n",
    "        max_steps = self.FLAGS.max_steps\n",
    "        state, _ = self.env.reset()\n",
    "        episode_return = 0.0\n",
    "        n_step_queue = NStepQueue(self.FLAGS.n_step, self.FLAGS.gamma)\n",
    "        logs = []\n",
    "\n",
    "        while self.step < max_steps:\n",
    "            # curriculum: adjust pole length based on training stage\n",
    "            if episode_return == 0.0:\n",
    "                if self.step < self.FLAGS.curri_bounds[0]:\n",
    "                    min_length, max_length = self.FLAGS.curri_ranges[0]\n",
    "                elif self.step < self.FLAGS.curri_bounds[1]:\n",
    "                    min_length, max_length = self.FLAGS.curri_ranges[1]\n",
    "                else:\n",
    "                    min_length, max_length = self.FLAGS.curri_ranges[2]\n",
    "                self.env.unwrapped.length = float(np.random.uniform(min_length, max_length))\n",
    "                n_step_queue = NStepQueue(self.FLAGS.n_step, self.FLAGS.gamma)\n",
    "\n",
    "            # take action\n",
    "            action = self.get_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # store n-step transition\n",
    "            n_step_queue.push(state, action, reward)\n",
    "            if n_step_queue.ready():\n",
    "                s0, a0, n_step_ret, s_n, done_flag = n_step_queue.pop_transition(next_state, done)\n",
    "                self.replay_buffer.push(s0, a0, n_step_ret, next_state, float(done))\n",
    "                n_step_queue.pop_left()\n",
    "\n",
    "            # optimize after warmup\n",
    "            loss = self.train_step()\n",
    "\n",
    "            # epsilon linear decay\n",
    "            self.step += 1\n",
    "            frac = min(1.0, self.step / self.FLAGS.epsilon_decay)\n",
    "            self.epsilon = self.FLAGS.epsilon_start + frac * (self.FLAGS.epsilon_end - self.FLAGS.epsilon_start)\n",
    "\n",
    "            # update target periodically\n",
    "            if self.step % self.FLAGS.target_update_every == 0:\n",
    "                self.update_target_network()\n",
    "\n",
    "            # log progress\n",
    "            state = next_state\n",
    "            episode_return += reward\n",
    "\n",
    "            if self.step % 10_000 == 0:\n",
    "                loss_str = None if loss is None else round(loss, 4)\n",
    "                print(f\"Step {self.step}: loss={loss_str}, epsilon={round(self.epsilon, 3)}\")\n",
    "\n",
    "            if loss is not None and self.step % 5_000 == 0:\n",
    "                logs.append((self.step, float(loss), float(self.epsilon)))\n",
    "\n",
    "            # reset at end of episode\n",
    "            if done:\n",
    "                n_step_queue.flush_to_buffer(next_state, self.replay_buffer, self.FLAGS.gamma)\n",
    "                state, _ = self.env.reset()\n",
    "                episode_return = 0.0\n",
    "\n",
    "        torch.save(self.q_network.state_dict(), save_path)\n",
    "        return logs, save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell trains our Double DQN agent on the CartPole environment using n-step returns and curriculum learning.\n",
    "\n",
    "The agent runs for 'max_steps' steps, gradually facing harder pole lengths as it learns.\n",
    "After training, the model weights are saved in the weights/ folder for later testing and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10000: loss=None, epsilon=0.968\n",
      "Step 20000: loss=None, epsilon=0.937\n",
      "Step 30000: loss=5.3117, epsilon=0.905\n",
      "Step 40000: loss=7.2062, epsilon=0.873\n",
      "Step 50000: loss=8.9543, epsilon=0.842\n",
      "Step 60000: loss=14.0968, epsilon=0.81\n",
      "Step 70000: loss=10.4785, epsilon=0.778\n",
      "Step 80000: loss=7.9353, epsilon=0.747\n",
      "Step 90000: loss=9.5936, epsilon=0.715\n",
      "Step 100000: loss=10.1984, epsilon=0.683\n",
      "Step 110000: loss=7.6405, epsilon=0.652\n",
      "Step 120000: loss=6.7442, epsilon=0.62\n",
      "Step 130000: loss=8.4809, epsilon=0.588\n",
      "Step 140000: loss=12.262, epsilon=0.557\n",
      "Step 150000: loss=8.0686, epsilon=0.525\n",
      "Step 160000: loss=12.917, epsilon=0.493\n",
      "Step 170000: loss=6.4957, epsilon=0.462\n",
      "Step 180000: loss=8.4733, epsilon=0.43\n",
      "Step 190000: loss=3.8195, epsilon=0.398\n",
      "Step 200000: loss=8.1442, epsilon=0.367\n",
      "Step 210000: loss=3.8937, epsilon=0.335\n",
      "Step 220000: loss=6.1034, epsilon=0.303\n",
      "Step 230000: loss=3.893, epsilon=0.272\n",
      "Step 240000: loss=1.8794, epsilon=0.24\n",
      "Step 250000: loss=5.6227, epsilon=0.208\n",
      "Step 260000: loss=1.442, epsilon=0.177\n",
      "Step 270000: loss=2.6184, epsilon=0.145\n",
      "Step 280000: loss=4.7265, epsilon=0.113\n",
      "Step 290000: loss=0.8177, epsilon=0.082\n",
      "Step 300000: loss=0.0731, epsilon=0.05\n",
      "Step 310000: loss=0.5214, epsilon=0.05\n",
      "Step 320000: loss=1.1633, epsilon=0.05\n",
      "Step 330000: loss=0.9353, epsilon=0.05\n",
      "Step 340000: loss=0.4318, epsilon=0.05\n",
      "Step 350000: loss=0.1021, epsilon=0.05\n",
      "Step 360000: loss=3.7708, epsilon=0.05\n",
      "Step 370000: loss=0.0732, epsilon=0.05\n",
      "Step 380000: loss=0.9606, epsilon=0.05\n",
      "Step 390000: loss=3.3639, epsilon=0.05\n",
      "Step 400000: loss=0.4903, epsilon=0.05\n",
      "Step 410000: loss=1.9254, epsilon=0.05\n",
      "Step 420000: loss=2.1047, epsilon=0.05\n",
      "Step 430000: loss=4.3316, epsilon=0.05\n",
      "Step 440000: loss=2.3463, epsilon=0.05\n",
      "Step 450000: loss=0.115, epsilon=0.05\n",
      "Step 460000: loss=1.9004, epsilon=0.05\n",
      "Step 470000: loss=4.589, epsilon=0.05\n",
      "Step 480000: loss=0.2908, epsilon=0.05\n",
      "Step 490000: loss=0.9371, epsilon=0.05\n",
      "Step 500000: loss=2.8185, epsilon=0.05\n",
      "Step 510000: loss=1.2053, epsilon=0.05\n",
      "Step 520000: loss=1.7907, epsilon=0.05\n",
      "Step 530000: loss=1.5655, epsilon=0.05\n",
      "Step 540000: loss=3.3832, epsilon=0.05\n",
      "Step 550000: loss=1.6703, epsilon=0.05\n",
      "Step 560000: loss=1.7775, epsilon=0.05\n",
      "Step 570000: loss=1.1162, epsilon=0.05\n",
      "Step 580000: loss=3.6345, epsilon=0.05\n",
      "Step 590000: loss=4.1306, epsilon=0.05\n",
      "Step 600000: loss=2.0777, epsilon=0.05\n",
      "Step 610000: loss=2.4798, epsilon=0.05\n",
      "Step 620000: loss=2.9948, epsilon=0.05\n",
      "Step 630000: loss=3.3722, epsilon=0.05\n",
      "Step 640000: loss=2.3701, epsilon=0.05\n",
      "Step 650000: loss=2.1553, epsilon=0.05\n",
      "Step 660000: loss=3.6553, epsilon=0.05\n",
      "Step 670000: loss=3.833, epsilon=0.05\n",
      "Step 680000: loss=2.8057, epsilon=0.05\n",
      "Step 690000: loss=1.0056, epsilon=0.05\n",
      "Step 700000: loss=1.6387, epsilon=0.05\n",
      "Step 710000: loss=4.6491, epsilon=0.05\n",
      "Step 720000: loss=3.9168, epsilon=0.05\n",
      "Step 730000: loss=2.5229, epsilon=0.05\n",
      "Step 740000: loss=5.101, epsilon=0.05\n",
      "Step 750000: loss=3.3742, epsilon=0.05\n",
      "Step 760000: loss=5.2624, epsilon=0.05\n",
      "Step 770000: loss=4.0016, epsilon=0.05\n",
      "Step 780000: loss=0.4311, epsilon=0.05\n",
      "Step 790000: loss=1.1594, epsilon=0.05\n",
      "Step 800000: loss=3.5297, epsilon=0.05\n",
      "training finished.\n",
      "saved to: weights/s1_ddqn.pth\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "env = gym.make(\"CartPole-v1\", render_mode=None)\n",
    "env.reset(seed=RANDOM_SEED)\n",
    "env.action_space.seed(RANDOM_SEED)\n",
    "\n",
    "agent = DDQN(env, FLAGS)\n",
    "\n",
    "logs, path = agent.train(save_path=\"weights/s1_ddqn.pth\")\n",
    "\n",
    "print(\"training finished.\")\n",
    "print(\"saved to:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default length: 500.0\n",
      "Pole length 0.6: 500.0\n",
      "Pole length 1.0: 500.0\n",
      "Pole length 1.4: 258.0\n",
      "Pole length 1.8: 143.0\n"
     ]
    }
   ],
   "source": [
    "# greedy evaluation (no exploration)\n",
    "def greedy_eval_once(agent, length=1.0, render=False):\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"human\" if render else None)\n",
    "    env.unwrapped.length = float(length)\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0.0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            x = torch.as_tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "            action = int(agent.q_network(x).argmax(1).item())\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = bool(terminated) or bool(truncated)\n",
    "        total_reward += float(reward)\n",
    "        state = next_state\n",
    "\n",
    "    env.close()\n",
    "    return total_reward\n",
    "\n",
    "print(\"Default length:\", greedy_eval_once(agent))\n",
    "for L in [0.6, 1.0, 1.4, 1.8]:\n",
    "    print(f\"Pole length {L:.1f}: {greedy_eval_once(agent, length=L)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.4482758620689655\n",
      "0.496551724137931\n",
      "0.5448275862068965\n",
      "0.5931034482758621\n",
      "0.6413793103448275\n",
      "0.6896551724137931\n",
      "0.7379310344827587\n",
      "0.7862068965517242\n",
      "0.8344827586206897\n",
      "0.8827586206896552\n",
      "0.9310344827586207\n",
      "0.9793103448275863\n",
      "1.0275862068965518\n",
      "1.0758620689655172\n",
      "1.1241379310344828\n",
      "1.1724137931034484\n",
      "1.2206896551724138\n",
      "1.2689655172413792\n",
      "1.3172413793103448\n",
      "1.3655172413793104\n",
      "1.4137931034482758\n",
      "1.4620689655172412\n",
      "1.510344827586207\n",
      "1.5586206896551724\n",
      "1.6068965517241378\n",
      "1.6551724137931036\n",
      "1.703448275862069\n",
      "1.7517241379310344\n",
      "1.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: bar_plot.png and experiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "# testing and plotting\n",
    "\n",
    "# same architecture as training\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def bar_plot(results):\n",
    "    data = results[0]\n",
    "    avgs = {k: v for k, v in data.items() if k.startswith('Avg_')}\n",
    "    stds = {k.replace('Avg', 'Std'): data[k.replace('Avg', 'Std')] for k in avgs.keys()}\n",
    "    sorted_keys = sorted(avgs.keys(), key=lambda x: float(x.split('_')[1]))\n",
    "    avg_values = [avgs[k] for k in sorted_keys]\n",
    "    std_values = [stds[k.replace('Avg', 'Std')] for k in sorted_keys]\n",
    "    overall_avg = float(np.mean(np.array(avg_values)))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(range(len(avg_values)), avg_values, yerr=std_values, capsize=5, alpha=0.7)\n",
    "    plt.xticks(range(len(avg_values)), [k.split('_')[1] for k in sorted_keys], rotation=45)\n",
    "    plt.xlabel('Pole length')\n",
    "    plt.ylabel('Episode length')\n",
    "    plt.title(f'Average score over all pole lengths = {round(overall_avg, 0)}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"bar_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "# official test loop per length (don’t change this logic)\n",
    "def test_pole_length(env, q_network):\n",
    "    wind = 25\n",
    "    state = env.reset()[0]\n",
    "    state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = q_network(state).argmax().item()\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = bool(terminated) or bool(truncated)\n",
    "        next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if 500 <= total_reward <= 1000:\n",
    "            if total_reward % wind == 0:\n",
    "                env.unwrapped.force_mag = 75\n",
    "        if total_reward > 1000:\n",
    "            env.unwrapped.force_mag = 25 + (0.01 * total_reward)\n",
    "    return total_reward\n",
    "\n",
    "def test_script():\n",
    "    pole_lengths = np.linspace(0.4, 1.8, 30)\n",
    "    all_results = []\n",
    "\n",
    "    # name of the trained neural network!\n",
    "    trained_nn = \"s1_ddqn.pth\"\n",
    "\n",
    "    results = {}\n",
    "    total_score = 0.0\n",
    "\n",
    "    for length in pole_lengths:\n",
    "        print(length)\n",
    "        pole_scores = []\n",
    "        for _ in range(10):\n",
    "            env = gym.make('CartPole-v1')\n",
    "            env.unwrapped.length = float(length)\n",
    "\n",
    "            state_dim = env.observation_space.shape[0]\n",
    "            action_dim = env.action_space.n\n",
    "            model = QNetwork(state_dim, action_dim)\n",
    "\n",
    "            # robust load across torch versions\n",
    "            try:\n",
    "                sd = torch.load(os.path.join(\"weights\", trained_nn), map_location=\"cpu\", weights_only=True)\n",
    "            except TypeError:\n",
    "                sd = torch.load(os.path.join(\"weights\", trained_nn), map_location=\"cpu\")\n",
    "            model.load_state_dict(sd)\n",
    "            model.eval()\n",
    "\n",
    "            score = test_pole_length(env, model)\n",
    "            pole_scores.append(score)\n",
    "\n",
    "        mean_score = float(np.mean(pole_scores))\n",
    "        std_score  = float(np.std(pole_scores))\n",
    "        total_score += mean_score\n",
    "        results[f\"Avg_{round(length, 2)}\"] = mean_score\n",
    "        results[f\"Std_{round(length, 2)}\"] = std_score\n",
    "\n",
    "    results[\"Total\"] = total_score\n",
    "    all_results.append(results)\n",
    "\n",
    "    bar_plot(all_results)\n",
    "\n",
    "    # saved it in CSV instead of excel\n",
    "    pd.DataFrame(all_results).to_csv(\"experiment_results.csv\", index=False)\n",
    "    print(\"Saved: bar_plot.png and experiment_results.csv\")\n",
    "\n",
    "# run the test\n",
    "test_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this strategy, I started from a standard Double DQN setup and gradually built on top of it with multi-step returns (n = 5) and a curriculum training schedule to help the agent generalize across different pole lengths.\n",
    "\n",
    "Initial runs with a plain DQN learned well at the default length but completely failed to transfer once the pole length changed. To fix this, I added n-step bootstrapping, which helped the agent propagate rewards further in time and stabilize learning. Then, I introduced a curriculum, starting with easier environments (pole length 0.8–1.2) and slowly expanding to harder ones (up to 1.8) as training progressed.\n",
    "\n",
    "Throughout training, I tested multiple hyperparameter settings. Lower learning rates made learning unstable and slow, so I increased it to 7 × 10⁻⁴ and extended the ε-decay to 275 k steps, allowing for more gradual exploration. After about 650 k total steps, the model reached steady performance across nearly all pole lengths.\n",
    "\n",
    "In the final evaluation, the agent achieved an average score of 347 over all pole lengths, more than double the baseline DQN (~140). Performance improved consistently as the pole length increased, peaking at 500 for long poles (1.4–1.8)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
